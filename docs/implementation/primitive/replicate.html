<head>
  <meta charset="utf-8">
  <link href="../../favicon.ico" rel="shortcut icon" type="image/x-icon"/>
  <link href="../../style.css" rel="stylesheet"/>
  <title>BQN: Implementation of Indices and Replicate</title>
</head>
<div class="nav">(<a href="https://github.com/mlochbaum/BQN">github</a>) / <a href="../../index.html">BQN</a> / <a href="../index.html">implementation</a> / <a href="index.html">primitive</a></div>
<h1 id="implementation-of-indices-and-replicate"><a class="header" href="#implementation-of-indices-and-replicate">Implementation of Indices and Replicate</a></h1>
<p>The replicate family of functions contains not just primitives but powerful tools for implementing other functionality. Most important is the boolean case, which can be used to ignore unwanted values without branching. Replicate by a constant amount (so <code><span class='Value'>ğ•¨</span></code> is a single number) is not too common in itself, but it's notable because it can be the fastest way to <a href="arithmetic.html#table-and-leading-axis">implement</a> outer products and arithmetic with prefix agreement. Fast implementations can be much better than the obvious C code, particularly for the boolean case.</p>
<table>
<thead>
<tr>
<th>Normal</th>
<th>Boolean</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#indices">Indices</a></td>
<td><a href="#booleans">Where</a></td>
</tr>
<tr>
<td><a href="#replicate">Replicate</a></td>
<td><a href="#booleans">Compress</a></td>
</tr>
<tr>
<td>(<a href="#constant-replicate">by constant</a>)</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="indices"><a class="header" href="#indices">Indices</a></h2>
<p>Because it's somewhat simpler to discuss, we'll begin with the case <code><span class='Function'>/</span><span class='Value'>ğ•©</span></code> where <code><span class='Value'>ğ•©</span></code> has an integer type (the boolean case is discussed <a href="#compress">below</a>). The obvious C loop works fine when the average of <code><span class='Value'>ğ•©</span></code> is large enough, because it auto-vectorizes to write many values at a time. When the average is smaller, this vectorization becomes less effective, but the main problem is branching, which takes many cycles for each element in <code><span class='Value'>ğ•©</span></code> if the values aren't predictable.</p>
<p>Indices is half of a <a href="sort.html#distribution-sorts">counting sort</a>: for sparse values, it's the slower half. Making it fast makes counting sort viable for much larger range-to-length ratios.</p>
<p>I know two main ways to tackle the branching problem. The elegant way is a three-pass method computing <code><span class='Function'>+</span><span class='Modifier'>`</span><span class='Function'>/</span><span class='Modifier'>â¼</span><span class='Function'>+</span><span class='Modifier'>`</span><span class='Value'>ğ•©</span></code>. First, zero out the result array. Then traverse <code><span class='Value'>ğ•©</span></code> with a running sum index and increment the result value at that index at each step. Then sum the result. Somehow C compilers still don't know how to vectorize a prefix sum so you'll need to do it manually for best performance. Three passes is bad for caching so this method needs to be done in blocks to work well for large arrays. A slightly faster variation is that instead of incrementing you can write indices and take a max-scan <code><span class='Function'>âŒˆ</span><span class='Modifier'>`</span></code> at the end.</p>
<p>The other way is to try to make the lengths less variable by rounding up. Later writes will overwrite earlier ones anyway. This gets messy. If the maximum value in <code><span class='Value'>ğ•©</span></code> is, say, 8, then generating indices is fairly fast: for each element, write 8 indices and then move the output pointer forward by that much. But if it's not bounded (and why would it be?) you'll end up with gaps. You could just accept some branching and write 8 more indices. You could also use a sparse <em>where</em> algorithm to get the indices of large elements in <code><span class='Value'>ğ•©</span></code>, and do the long writes for those either before or after the short ones. Overall I'm kind of skeptical of these approaches here. However, they are definitely valid for constant Replicate, where <code><span class='Value'>ğ•¨</span></code> is inherently bounded.</p>
<h2 id="replicate"><a class="header" href="#replicate">Replicate</a></h2>
<p>Most techniques for Indices can be adapted to Replicate, and the same considerations about branching apply.</p>
<p>An additional approach that becomes available is essentially <code><span class='Function'>/</span><span class='Modifier2'>âŠ¸</span><span class='Function'>âŠ</span></code>: apply Indices to portions of <code><span class='Value'>ğ•¨</span></code> with the result in a temporary buffer, and select to produce the result. With small enough sections you can use 8-bit indices which can save time. As far as I can tell this method isn't an improvement for Replicate but is for the boolean case, Compress.</p>
<p>The running sum method needs to be modified slightly: instead of incrementing result values by one always, add the difference between the current value in <code><span class='Value'>ğ•©</span></code> and the previous one. It's possible to use xor instead of addition and subtraction but it shouldn't ever make much of a difference to performance. In the boolean case xor-ing trailing bits instead of single bits allows part of an xor-scan to be skipped; see <a href="https://www.dyalog.com/blog/2018/06/expanding-bits-in-shrinking-time/">Expanding Bits in Shrinking Time</a>.</p>
<h3 id="constant-replicate"><a class="header" href="#constant-replicate">Constant replicate</a></h3>
<p>The case where <code><span class='Value'>ğ•¨</span></code> is constant is useful for outer products and leading-axis extension (<a href="arithmetic.html#table-and-leading-axis">this section</a>), where elements of one argument need to be repeated a few times. This connection is also discussed in <a href="https://www.dyalog.com/blog/2018/06/expanding-bits-in-shrinking-time/">Expanding Bits</a>.</p>
<p>The same approaches work, but the branches in the branchless ones become a lot more predictable. So the obvious loops are now okay instead of bad even for small values. C compilers will generate decent code for constant small numbersâ€”better for powers of two, but still not optimal it seems?</p>
<p>For top performance, the result should be constructed from one shuffle per output, and some haggling with lanes for odd values in AVX. But this takes <code><span class='Value'>ğ•¨</span></code> shuffle instructions, so handling all constants up to some bound is quadratic in code size (JIT compiling might help, but generating a lot of code is bad for short <code><span class='Value'>ğ•©</span></code>). On 1- to 8-byte types, CBQN has a complicated mix of AVX2 methods to get high peformance with tolerable code size. From fastest to slowest:</p>
<ul>
<li>Sizes 2 to 7 have dedicated shuffle code.</li>
<li>Small composite sizes <code><span class='Value'>ğ•¨</span><span class='Function'>=</span><span class='Value'>l</span><span class='Function'>Ã—</span><span class='Value'>f</span></code>, where <code><span class='Value'>f</span></code> has a dedicated shuffle, are split into <code><span class='Value'>l</span><span class='Function'>/</span><span class='Value'>f</span><span class='Function'>/</span><span class='Value'>ğ•©</span></code>.</li>
<li>Other small sizes use a function that always reads 1 vector and writes 4 per iteration, using shuffle vectors from a table to generate them. This requires tail handling and uses some tricks to pack the tables to a reasonable size.</li>
<li>Sizes where one element fills multiple vectors write broadcasted vectors, overlapping the last two writes to avoid any tail handling. There are unrolled loops for less than 4 vectors.</li>
</ul>
<h4 id="constant-replicate-boolean"><a class="header" href="#constant-replicate-boolean">Constant replicate boolean</a></h4>
<p>On booleans, we also use a mix of methods, which for small constants is based on factoring into a power of two times an odd number. Divisors of 8 are handled with various ad-hoc shuffling (and sometimes we replicate by 8 and then replicate as 1-byte data). Odd factors less than 64 are always handled with the <a href="fold.html#the-modular-bit-permutation">modular permutation</a>. This alone can only place each bit at its initial index times <code><span class='Value'>ğ•¨</span></code>, so to spread each bit we want to shift up by <code><span class='Value'>ğ•¨</span></code> and subtract. A key trick is to rotate the permuted word, which combines all the bits, instead of shifting after splitting it up. When handling the lowest <code><span class='Value'>ğ•¨</span></code> bits of each word, the top bit will be there but the bottom bit won't, so you have to subtract 1 if any of the bottom <code><span class='Value'>ğ•¨</span></code> bits of the top bit is setâ€”with this, any cross-word carrying is eliminated!</p>
<p>With AVX2 we can also get useful work out of the modular permutation above width 64 and up to 256, by constructing a boundary mask that always has one bit: it is the boundary in each word that has one, or is the same as the previous mask. This is constructed as <code><span class='Number'>1</span><span class='Function'>&lt;&lt;</span><span class='Paren'>(</span><span class='Value'>s&amp;</span><span class='Number'>63</span><span class='Paren'>)</span></code>, where the shift amount <code><span class='Value'>s</span></code> is equal to the distance from the end of a given word to the previous boundaryâ€”that is, a negative number in the range [-<code><span class='Value'>ğ•¨</span></code>,0). Then bitwise-and with a permuted 64-bit word picks out the bit value that should go at the end of the word. If <code><span class='Value'>s</span> <span class='Function'>&gt;=</span> <span class='Function'>-</span><span class='Number'>64</span></code>, then this is the entire word, and otherwise the other bit can be incorporated using the rotation trick and some xor-based logic. I haven't found an analogue of the horizontal-vertical mask decomposition for <code><span class='Value'>ğ•¨</span><span class='Function'>&lt;</span><span class='Number'>64</span></code>; the distance tracking and shifting is substantially slower.</p>
<p>Otherwise, the scalar method for <code><span class='Value'>ğ•¨</span><span class='Function'>&gt;</span><span class='Number'>64</span></code> is, for each bit in <code><span class='Value'>ğ•©</span></code>, to write a boundary word and then some number of constant words. This can be done with a fixed number of writes, increasing the speed at smaller <code><span class='Value'>ğ•¨</span></code> by avoiding branch prediction. Every iteration writes <code><span class='Value'>w</span><span class='Function'>/</span><span class='Number'>64</span> <span class='Function'>-</span> <span class='Number'>1</span></code> or <code><span class='Value'>w</span><span class='Function'>/</span><span class='Number'>64</span></code> constant words. First write the last one, then <code><span class='Value'>w</span><span class='Function'>/</span><span class='Number'>64</span> <span class='Function'>-</span> <span class='Number'>1</span></code> from the starting point. They'll overlap if necessary to give the right length.</p>
<h2 id="booleans"><a class="header" href="#booleans">Booleans</a></h2>
<p>The case with a boolean replication amount is called Where or Compress, based on APL names for these functions from before Replicate was extended to natural numbers.</p>
<p>The standard branchless strategy is to write each result value regardless of whether it should actually be included, then increment the result pointer only if it is. Careful as this writes an element past the end in many situations. However, other methods described here are much faster and should be used when there's more implementation time available. All the good methods process multiple bits at once, giving a two-level model: an outer replicate-like pattern that increments by the <em>sum</em> of a group of booleans, as well as an inner pattern based on the individual 0s and 1s.</p>
<p>There are x86 instructions for Compress on booleans in BMI2 and other types in AVX-512. If these aren't available then boolean Compress has to be implemented with some shift-based emulation, and otherwise lookup tables seem to be best for Compress and Where (for completeness, boolean-result Where with can have at most two output indices so it hardly matters how fast it is).</p>
<h3 id="compress-instructions"><a class="header" href="#compress-instructions">Compress instructions</a></h3>
<p>Some x86 extensions have instructions for Compress: in BMI2, pext is compress on 64 bit booleans, and there are compress instructions for 32- and 64-bit types in AVX-512 F, and 8- and 16-bit in the later AVX-512 VBMI2. The AVX-512 compresses can be used for Where as well by applying to a vector of indices.</p>
<p>For the time being it seems the compress-store variants should never be used, particularly on Zen4 (search vpcompressd <a href="https://www.mersenneforum.org/showthread.php?p=614191">here</a>). Instead, use in-register compress, then store with a mask. You have to compute the boolean argument's popcount anyway, so the mask for popcount <code><span class='Value'>p</span></code> is <code><span class='Paren'>(</span><span class='Number'>1</span><span class='Function'>&lt;&lt;</span><span class='Value'>p</span><span class='Paren'>)</span><span class='Function'>-</span><span class='Number'>1</span></code>, except that the <code><span class='Value'>p</span><span class='Function'>==</span><span class='Number'>64</span></code> case needs to be worked around to avoid shifting by more than a register width.</p>
<p>For pext, you do have to figure out how to write the output given that it comes in partial words. Best I have is to accumulate into a result word and write when it fills up. This creates some branch prediction overhead at density below about 1/8 so I wonder if there's some kind of semi-sparse method that can address that.</p>
<p>Langdale also <a href="https://branchfree.org/2018/05/22/bits-to-indexes-in-bmi2-and-avx-512/">describes</a> another way to get 1-byte indices using only AVX-512 F and BMI2. I haven't looked into this in detail.</p>
<h3 id="table-based-where-and-compress"><a class="header" href="#table-based-where-and-compress">Table-based Where and Compress</a></h3>
<p>Without hardware support, nothing beats a lookup table as far as I can tell. The two limits on size are the output unit (for example 16 bytes with SSE) and at most 8 bits at a timeâ€”with 16 the table's just too big. A single 2KB table mapping each byte to indices (for example 10001100 to 0x070302) can be shared by all the 8-bit cases of Where and Compress. For some compress cases a larger non-shared table might be a touch faster, but this doesn't seem like a good tradeoff for an interpreter. <a href="https://lemire.me/blog/2018/03/08/iterating-over-set-bits-quickly-simd-edition/">Lemire explains</a> how to do it with an 8KB table and powturbo mentions the 2KB version in a comment.</p>
<p>To sum a byte, popcount is best if you have it and a dedicated table also works. Another way is to store the count minus one in the top byte of the index table, since that byte is only used by 0xff where it has value 7. Can be slower than a separate table but it doesn't take up cache space.</p>
<p>Here's a concrete description for 1-byte Where, the only case that works at full speed without any vector instructions. For each byte, get the corresponding indices, add an increment, and write them to the current index in the output. Then increase the output index by the byte's sum. The next indices will overlap the 8 bytes written, with the actual indices kept and junk values at the end overwritten. The increment added is an 8-byte value where each byte contains the current input index (always a multiple of 8); it can be added or bitwise or-ed with the lookup value.</p>
<p>For 2-byte and 4-byte Where, those bytes need to be expanded with top bits, which is easy enough with vector instructions. The top bits are always constant within one iteration, so they can be updated at between loop iterations.</p>
<p>For Compress you need a shuffle instruction. For 1-byte types an SSSE3 or NEON shuffle applies directly; for 2-byte you'll have to interleave <code><span class='Number'>2</span><span class='Function'>Ã—</span><span class='Value'>i</span></code> with <code><span class='Number'>1</span><span class='Function'>+</span><span class='Number'>2</span><span class='Function'>Ã—</span><span class='Value'>i</span></code> given indices <code><span class='Value'>i</span></code> if you don't want to make a table that precomputes that. But it writes 16 bytes at a time instead of 8 so it'll actually be closer to saturating memory bandwidth. For larger types, when you can only write 4 elements you may as well do the precomputed table as it's only 16 entries. And AVX2's vpermd (permutevar8x32) is essential for 4- and 8-byte values because it goes across lanes. Here's how many elements at a time we handle in CBQN and whether we get them from the large shared table or a small custom one.</p>
<table>
<thead>
<tr>
<th>Bytes</th>
<th>SSSE3 or NEON</th>
<th>AVX2</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>8, large</td>
<td>-</td>
</tr>
<tr>
<td>2</td>
<td>8, large+interleave</td>
<td>-</td>
</tr>
<tr>
<td>4</td>
<td>4, small</td>
<td>8, large+convert</td>
</tr>
<tr>
<td>8</td>
<td></td>
<td>4, small</td>
</tr>
</tbody>
</table>
<p>To handle 4 bits we unroll by 2 to process a byte of <code><span class='Value'>ğ•¨</span></code> at a time. Instead of incrementing by the popcount of each half sequentially, increment the result pointer by the count of the entire byte at the end of an iteration. The second half uses the result pointer plus the count of the first half, but discards this pointer.</p>
<p>All of these methods can write past the end of the result (and an AVX2 masked write didn't have good performance when I tried it). So there needs to be some way to prevent this from sowing destruction. Overallocating works, and one particular case is that generating 1-byte indices for temporary use can always be done safely in a 256-byte buffer. Since an overallocation in CBQN is permanently wasted space, what we did is to move the result pointer to a small stack-allocated buffer when there's no longer space in the result for a full write. After finishing in that buffer, we copy the values to the real result with one or two vector writes that are appropriately masked.</p>
<p>Finally, when you don't have a shuffle instruction, the best method I know is just to generate indices in blocks using a table and select with those one at a time.</p>
<h3 id="boolean-compress"><a class="header" href="#boolean-compress">Boolean compress</a></h3>
<p>When you don't have pext you have to emulate it. Two strategies are described in Hacker's Delight, although neither reaches its full potential there. The one given in 7-4 is due to Guy Steele, and sketched in 7-6 is another method I'll call &quot;pairwise&quot;, which the book claims isn't practical in software. As shown, both take logÂ²(w) instructions for word size w. I will describe below how Guy Steele's method can be brought down to log(w) using sum-scan rather than xor-scan, and the pairwise method can also be done in log(w) vector instructions if shifting each element by a variable amount is supported. CBQN's implementations work on 64-bit words or vectors of them, and always begin with some version of Guy Steele. The pairwise method is used beginning from size 8 on NEON and 16 on AVX2 to take advantage of per-element shifts.</p>
<p>On Zen, Zen+, and Zen 2 architectures, pext is micro-coded as a loop over set bits and should not be used. The cost ranges from a few cycles to hundreds; measurements such as uops.info apparently use an argument that's 0 or close to it, so they underreport.</p>
<svg viewBox='-36 -68 758.4 493.408'>
  <g fill='currentColor' font-family='BQN,monospace' font-size='16'>
    <rect class='code' stroke-width='1.5' rx='12' x='-20' y='-60' width='726.4' height='477.408'/>
    <g class='yellow' stroke-width='4' opacity='0.2'>
      <path d='M14.4 154L14.4 172M24 154L24 172M34.6 154L42.2 172M52.8 154L52.8 172M62.4 154L62.4 172M72 154L72 172M93.2 154L108.4 172M120 154L120 172M132.6 154L184.2 172M196.8 154L196.8 172M206.4 154L206.4 172M216 154L216 172M235.2 154L235.2 172M244.8 154L244.8 172M254.4 154L254.4 172M264 154L264 172M302.4 154L302.4 172'/>
      <path d='M15.4 192L23 214.56M25 192L32.6 214.56M43.2 192L43.2 214.56M52.8 192L52.8 214.56M65.4 192L88.2 214.56M75 192L97.8 214.56M110.4 192L110.4 214.56M120 192L120 214.56M187.2 192L187.2 214.56M196.8 192L196.8 214.56M206.4 192L206.4 214.56M216 192L216 214.56M235.2 192L235.2 214.56M244.8 192L244.8 214.56M254.4 192L254.4 214.56M264 192L264 214.56M302.4 192L302.4 214.56'/>
      <path d='M27 234.56L49.8 262.227M36.6 234.56L59.4 262.227M46.2 234.56L69 262.227M55.8 234.56L78.6 262.227M91.2 234.56L91.2 262.227M100.8 234.56L100.8 262.227M110.4 234.56L110.4 262.227M120 234.56L120 262.227M188.2 234.56L195.8 262.227M197.8 234.56L205.4 262.227M207.4 234.56L215 262.227M217 234.56L224.6 262.227M235.2 234.56L235.2 262.227M244.8 234.56L244.8 262.227M254.4 234.56L254.4 262.227M264 234.56L264 262.227M302.4 234.56L302.4 262.227'/>
      <path d='M55.8 282.227L117 315.614M65.4 282.227L126.6 315.614M75 282.227L136.2 315.614M84.6 282.227L145.8 315.614M94.2 282.227L155.4 315.614M103.8 282.227L165 315.614M113.4 282.227L174.6 315.614M123 282.227L184.2 315.614M196.8 282.227L196.8 315.614M206.4 282.227L206.4 315.614M216 282.227L216 315.614M225.6 282.227L225.6 315.614M235.2 282.227L235.2 315.614M244.8 282.227L244.8 315.614M254.4 282.227L254.4 315.614M264 282.227L264 315.614M302.4 282.227L302.4 315.614'/>
      <path d='M123 335.614L145.8 375.408M132.6 335.614L155.4 375.408M142.2 335.614L165 375.408M151.8 335.614L174.6 375.408M161.4 335.614L184.2 375.408M171 335.614L193.8 375.408M180.6 335.614L203.4 375.408M190.2 335.614L213 375.408M199.8 335.614L222.6 375.408M209.4 335.614L232.2 375.408M219 335.614L241.8 375.408M228.6 335.614L251.4 375.408M238.2 335.614L261 375.408M247.8 335.614L270.6 375.408M257.4 335.614L280.2 375.408M267 335.614L289.8 375.408M302.4 335.614L302.4 375.408'/>
    </g>
    <g class='bluegreen' opacity='0.4' stroke-width='1'>
      <path d='M398.4 135.5V191M417.6 135.5V233.56M436.8 135.5V191M456 135.5V281.227M475.2 135.5V191M494.4 135.5V233.56M513.6 135.5V191M532.8 135.5V334.614M552 135.5V191M571.2 135.5V233.56M590.4 135.5V191M609.6 135.5V281.227M628.8 135.5V191M648 135.5V233.56M667.2 135.5V191'/>
      <rect x='0' y='135' width='9.6' height='18'/>
      <rect x='38.4' y='135' width='9.6' height='18'/>
      <rect x='76.8' y='135' width='9.6' height='18'/>
      <rect x='96' y='135' width='19.2' height='18'/>
      <rect x='134.4' y='135' width='57.6' height='18'/>
      <rect x='220.8' y='135' width='9.6' height='18'/>
      <rect x='268.8' y='135' width='28.8' height='18'/>
      <rect x='379.2' y='135' width='9.6' height='18'/>
      <rect x='417.6' y='135' width='9.6' height='18'/>
      <rect x='456' y='135' width='9.6' height='18'/>
      <rect x='475.2' y='135' width='19.2' height='18'/>
      <rect x='513.6' y='135' width='57.6' height='18'/>
      <rect x='600' y='135' width='9.6' height='18'/>
      <rect x='648' y='135' width='28.8' height='18'/>
      <rect x='0' y='173' width='9.6' height='18'/>
      <rect x='28.8' y='173' width='9.6' height='18'/>
      <rect x='76.8' y='173' width='28.8' height='18'/>
      <rect x='124.8' y='173' width='57.6' height='18'/>
      <rect x='220.8' y='173' width='9.6' height='18'/>
      <rect x='268.8' y='173' width='28.8' height='18'/>
      <rect x='379.2' y='173' width='9.6' height='18'/>
      <rect x='417.6' y='173' width='9.6' height='18'/>
      <rect x='456' y='173' width='9.6' height='18'/>
      <rect x='475.2' y='173' width='19.2' height='18'/>
      <rect x='513.6' y='173' width='57.6' height='18'/>
      <rect x='590.4' y='173' width='9.6' height='18'/>
      <rect x='648' y='173' width='28.8' height='18'/>
      <rect x='0' y='215.56' width='19.2' height='18'/>
      <rect x='57.6' y='215.56' width='28.8' height='18'/>
      <rect x='124.8' y='215.56' width='57.6' height='18'/>
      <rect x='220.8' y='215.56' width='9.6' height='18'/>
      <rect x='268.8' y='215.56' width='28.8' height='18'/>
      <rect x='379.2' y='215.56' width='9.6' height='18'/>
      <rect x='417.6' y='215.56' width='9.6' height='18'/>
      <rect x='456' y='215.56' width='28.8' height='18'/>
      <rect x='494.4' y='215.56' width='19.2' height='18'/>
      <rect x='532.8' y='215.56' width='48' height='18'/>
      <rect x='648' y='215.56' width='28.8' height='18'/>
      <rect x='0' y='263.227' width='48' height='18'/>
      <rect x='124.8' y='263.227' width='67.2' height='18'/>
      <rect x='268.8' y='263.227' width='28.8' height='18'/>
      <rect x='379.2' y='263.227' width='19.2' height='18'/>
      <rect x='456' y='263.227' width='48' height='18'/>
      <rect x='532.8' y='263.227' width='48' height='18'/>
      <rect x='609.6' y='263.227' width='28.8' height='18'/>
      <rect x='0' y='316.614' width='115.2' height='18'/>
      <rect x='268.8' y='316.614' width='28.8' height='18'/>
      <rect x='379.2' y='316.614' width='67.2' height='18'/>
      <rect x='532.8' y='316.614' width='76.8' height='18'/>
      <rect x='0' y='376.408' width='144' height='18'/>
      <rect x='379.2' y='376.408' width='144' height='18'/>
    </g>
    <g class='purple' stroke-width='1.5'>
      <path d='M19.2 14H28.8M38.4 14H57.6M67.2 14H76.8M96 14H124.8M134.4 14H201.6M211.2 14H220.8M240 14H249.6M259.2 14H268.8'/>
      <path d='M28.8 36H57.6M76.8 36H124.8M201.6 36H220.8M249.6 36H268.8'/>
      <path d='M57.6 58H124.8M220.8 58H268.8'/>
      <path d='M124.8 80H268.8'/>
      <path d='M268.8 102H307.2'/>
      <g stroke-width='3'>
        <path d='M19.2 154H28.8M38.4 154H57.6M67.2 154H76.8M96 154H124.8M134.4 154H201.6M211.2 154H220.8M240 154H249.6M259.2 154H268.8M388.8 154H398.4M408 154H417.6M427.2 154H436.8M446.4 154H456M465.6 154H475.2M484.8 154H494.4M504 154H513.6M523.2 154H532.8M542.4 154H552M561.6 154H571.2M580.8 154H590.4M600 154H609.6M619.2 154H628.8M638.4 154H648M657.6 154H667.2M676.8 154H686.4'/>
        <path d='M28.8 192H57.6M76.8 192H124.8M201.6 192H220.8M249.6 192H268.8M398.4 192H417.6M436.8 192H456M475.2 192H494.4M513.6 192H532.8M552 192H571.2M590.4 192H609.6M628.8 192H648M667.2 192H686.4'/>
        <path d='M57.6 234.56H124.8M220.8 234.56H268.8M417.6 234.56H456M494.4 234.56H532.8M571.2 234.56H609.6M648 234.56H686.4'/>
        <path d='M124.8 282.227H268.8M456 282.227H532.8M609.6 282.227H686.4'/>
        <path d='M268.8 335.614H307.2M532.8 335.614H686.4'/>
      </g>
      <path d='M42.2 154L34.6 172M99.8 154L92.2 172M109.4 154L101.8 172M138.2 154L130.6 172M147.8 154L140.2 172M157.4 154L149.8 172M167 154L159.4 172M176.6 154L169 172M186.2 154L178.6 172M489.6 154L489.6 172M528 154L528 172M547.2 154L547.2 172M566.4 154L566.4 172M603.8 154L596.2 172M662.4 154L662.4 172'/>
      <path d='M31.6 192L16.4 214.56M79.6 192L64.4 214.56M89.2 192L74 214.56M98.8 192L83.6 214.56M479 192L471.4 214.56M488.6 192L481 214.56M516.4 192L501.2 214.56M526 192L510.8 214.56M556.8 192L556.8 214.56M566.4 192L566.4 214.56M593.2 192L578 214.56M672 192L672 214.56'/>
      <path d='M59.4 234.56L27 262.227M69 234.56L36.6 262.227M78.6 234.56L46.2 262.227M222.6 234.56L190.2 262.227M419.4 234.56L396.6 262.227M498.2 234.56L490.6 262.227M507.8 234.56L500.2 262.227M576 234.56L576 262.227M649.8 234.56L617.4 262.227M659.4 234.56L627 262.227M669 234.56L636.6 262.227'/>
      <path d='M126.6 282.227L55.8 315.614M136.2 282.227L65.4 315.614M145.8 282.227L75 315.614M155.4 282.227L84.6 315.614M165 282.227L94.2 315.614M174.6 282.227L103.8 315.614M184.2 282.227L113.4 315.614M457.8 282.227L406.2 315.614M467.4 282.227L415.8 315.614M477 282.227L425.4 315.614M486.6 282.227L435 315.614M496.2 282.227L444.6 315.614M611.4 282.227L588.6 315.614M621 282.227L598.2 315.614M630.6 282.227L607.8 315.614'/>
      <path d='M270.6 335.614L123 375.408M280.2 335.614L132.6 375.408M289.8 335.614L142.2 375.408M534.6 335.614L454.2 375.408M544.2 335.614L463.8 375.408M553.8 335.614L473.4 375.408M563.4 335.614L483 375.408M573 335.614L492.6 375.408M582.6 335.614L502.2 375.408M592.2 335.614L511.8 375.408M601.8 335.614L521.4 375.408'/>
    </g>
    <text textLength='307.2' dy='0.32em' x='0' y='6'>0<tspan class='Number'>111</tspan><tspan class='Modifier'>0</tspan><tspan class='Number'>111</tspan>0<tspan class='Number'>1</tspan><tspan class='Modifier'>00</tspan><tspan class='Number'>11</tspan><tspan class='Modifier'>000000</tspan><tspan class='Number'>111</tspan>0<tspan class='Number'>1111</tspan>000<tspan class='Number'>1</tspan></text>
    <text textLength='307.2' dy='0.32em' x='0' y='28'>00<tspan class='Number'>1</tspan><tspan class='Modifier'>00</tspan><tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan><tspan class='Modifier'>0000</tspan><tspan class='Number'>1</tspan>0000000<tspan class='Number'>1</tspan><tspan class='Modifier'>0</tspan><tspan class='Number'>1</tspan>00<tspan class='Number'>1</tspan><tspan class='Modifier'>0</tspan><tspan class='Number'>1</tspan>0000</text>
    <text textLength='307.2' dy='0.32em' x='0' y='50'>00000<tspan class='Number'>1</tspan><tspan class='Modifier'>000000</tspan><tspan class='Number'>1</tspan>000000000<tspan class='Number'>1</tspan><tspan class='Modifier'>0000</tspan><tspan class='Number'>1</tspan>0000</text>
    <text textLength='307.2' dy='0.32em' x='0' y='72'>000000000000<tspan class='Number'>1</tspan><tspan class='Modifier'>00000000000000</tspan><tspan class='Number'>1</tspan>0000</text>
    <text textLength='307.2' dy='0.32em' x='0' y='94'>000000000000000000000000000<tspan class='Number'>1</tspan><tspan class='Modifier'>0000</tspan></text>
    <text textLength='307.2' dy='0.32em' x='0' y='144'><tspan class='Number'>1</tspan>0000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>00000<tspan class='Number'>1111</tspan>000<tspan class='Number'>1</tspan>0000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='0' y='182'><tspan class='Number'>1</tspan>0000000<tspan class='Number'>11</tspan>00000<tspan class='Number'>1111</tspan>0000<tspan class='Number'>1</tspan>0000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='0' y='224.56'><tspan class='Number'>1</tspan>00000<tspan class='Number'>11</tspan>0000000<tspan class='Number'>1111</tspan>0000<tspan class='Number'>1</tspan>0000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='0' y='272.227'><tspan class='Number'>1</tspan>0<tspan class='Number'>11</tspan>00000000000<tspan class='Number'>11111</tspan>00000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='0' y='325.614'><tspan class='Number'>1</tspan>0<tspan class='Number'>11</tspan>000<tspan class='Number'>11111</tspan>0000000000000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='0' y='385.408'><tspan class='Number'>1</tspan>0<tspan class='Number'>11</tspan>000<tspan class='Number'>111111</tspan>0<tspan class='Number'>1</tspan>00000000000000000</text>
    <text textLength='307.2' dy='0.32em' x='379.2' y='144'><tspan class='Number'>1</tspan>0000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>00000<tspan class='Number'>1111</tspan>000<tspan class='Number'>1</tspan>0000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='379.2' y='182'><tspan class='Number'>1</tspan>0000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>00000<tspan class='Number'>1111</tspan>00<tspan class='Number'>1</tspan>00000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='379.2' y='224.56'><tspan class='Number'>1</tspan>0000000<tspan class='Number'>11</tspan>000000<tspan class='Number'>11111</tspan>0000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='379.2' y='272.227'><tspan class='Number'>1</tspan>0000000<tspan class='Number'>11</tspan>000000<tspan class='Number'>11111</tspan>000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>00000</text>
    <text textLength='307.2' dy='0.32em' x='379.2' y='325.614'><tspan class='Number'>1</tspan>0<tspan class='Number'>11</tspan>000000000000<tspan class='Number'>111111</tspan>0<tspan class='Number'>1</tspan>00000000</text>
    <text textLength='307.2' dy='0.32em' x='379.2' y='385.408'><tspan class='Number'>1</tspan>0<tspan class='Number'>11</tspan>000<tspan class='Number'>111111</tspan>0<tspan class='Number'>1</tspan>00000000000000000</text>
    <text textLength='307.2' dy='0.32em' x='379.2' y='6'><tspan class='Modifier'>0</tspan>1<tspan class='Modifier'>1</tspan>1<tspan class='Modifier'>0</tspan>1<tspan class='Modifier'>1</tspan>1<tspan class='Modifier'>0</tspan>1<tspan class='Modifier'>0</tspan>0<tspan class='Modifier'>1</tspan>1<tspan class='Modifier'>0</tspan>0<tspan class='Modifier'>0</tspan>0<tspan class='Modifier'>0</tspan>0<tspan class='Modifier'>1</tspan>1<tspan class='Modifier'>1</tspan>0<tspan class='Modifier'>1</tspan>1<tspan class='Modifier'>1</tspan>1<tspan class='Modifier'>0</tspan>0<tspan class='Modifier'>0</tspan>1</text>
    <text textLength='297.6' dy='0.32em' x='379.2' y='28'><tspan class='Modifier'>1</tspan>2<tspan class='Modifier'>1</tspan>2<tspan class='Modifier'>1</tspan>0<tspan class='Modifier'>2</tspan>0<tspan class='Modifier'>0</tspan>0<tspan class='Modifier'>2</tspan>1<tspan class='Modifier'>2</tspan>2<tspan class='Modifier'>0</tspan>1</text>
    <text textLength='278.4' dy='0.32em' x='379.2' y='50'><tspan class='Modifier'>3</tspan>3<tspan class='Modifier'>1</tspan>2<tspan class='Modifier'>0</tspan>3<tspan class='Modifier'>4</tspan>1</text>
    <text textLength='240' dy='0.32em' x='379.2' y='72'><tspan class='Modifier'>6</tspan>3<tspan class='Modifier'>3</tspan>5</text>
    <text textLength='163.2' dy='0.32em' x='379.2' y='94'><tspan class='Modifier'>9</tspan>8</text>
    <g font-size='22' text-anchor='middle'>
      <text dy='0.33em' x='153.6' y='-32'>Guy Steele</text>
      <text dy='0.33em' x='532.8' y='-32'>Pairwise</text>
      <text dy='0.33em' x='343.2' y='4'><tspan class='Function'>Â¬</tspan><tspan class='Value'>ğ•¨</tspan></text>
      <text dy='0.33em' x='343.2' y='142'><tspan class='Value'>ğ•¨</tspan><tspan class='Function'>âˆ§</tspan><tspan class='Value'>ğ•©</tspan></text>
      <text dy='0.33em' x='343.2' y='383.408'><tspan class='Value'>ğ•¨</tspan><tspan class='Function'>/</tspan><tspan class='Value'>ğ•©</tspan></text>
    </g>
  </g>
</svg>

<p>Both strategies move bits of <code><span class='Value'>ğ•©</span></code> with the masked shift <code><span class='Paren'>(</span><span class='Value'>x</span> <span class='Value'>&amp;</span> <span class='Value'>m</span><span class='Paren'>)</span><span class='Function'>&gt;&gt;</span><span class='Value'>sh</span> <span class='Function'>|</span> <span class='Paren'>(</span><span class='Value'>x</span> <span class='Value'>&amp;~</span> <span class='Value'>m</span><span class='Paren'>)</span></code>. Guy Steele's method naturally uses fixed shifts 1, 2, 4, up to w/2 with variable masks, while the pairwise method uses fixed masks and variable shift amounts less than or equal to those powers of two. Each bit of <code><span class='Value'>ğ•©</span></code> needs to eventually be shifted down by the number of zeros in <code><span class='Value'>ğ•¨</span></code> below it, for a maximum possible shift of w-1 if only the top bit is used.</p>
<p>The pairwise method fits a recursive description: split the arguments in half and compress each side in place, then join them by shifting the top half down by the number of zeros in the bottom half (and also get the total count of zeros by adding counts from the two sides). The width 1 base case would be <code><span class='Value'>w</span> <span class='Value'>&amp;</span> <span class='Value'>x</span></code> for the compressed data, and <code><span class='Value'>~w</span></code> for the zero counts, but all my code uses Guy Steele's method to start at a larger width. If you don't have an instruction to shift all the top halves by different amounts, it's possible to emulate it, but I no longer think this is wanted for the fastest algorithms, so it's collapsed below.</p>
<details><summary>Hopefully obselete</summary>

<p>In order to perform a variable-shift on the top halves, they should be isolated first (it won't be easy to separate them from bottom halves later), and then shifted by powers of two with masks spanning both top and bottom groups. The mask for a shift by <code><span class='Number'>1</span><span class='Function'>&lt;&lt;</span><span class='Value'>k</span></code> is 1 where the zero count has bit <code><span class='Value'>k</span></code> set. Naively, this wastes nearly a whole bit: for example merging groups of size 4 may need a shift anywhere from 0 to 4, requiring 3 bits but the top one's only used for 4 exactly! I found some twiddling that mitigates this by not using this bit but instead leaving a group out of the shifted part if it would shift by 0, and tacking on a constant shift by 1 for the rest.</p>
<p>A too-wide shift may also be used to perform a few steps at once, for example to go from 8 to 32 bits in AVX2: get total offsets with a multiply (e.g. by 0x010101â€¦), then apply them individually. That is, pull out each group with a mask, shift by its offset, and or all these shifted words together.</p>
</details>

<p>Guy Steele shifts each bit directly by the right amount, that is, the number of zeros below it. The sum <code><span class='Function'>+</span><span class='Modifier'>`</span><span class='Value'>m</span><span class='Gets'>â†</span><span class='Function'>Â¬</span><span class='Value'>ğ•¨</span></code> is constructed bit-by-bit: the first shift mask <code><span class='Function'>â‰ </span><span class='Modifier'>`</span><span class='Value'>m</span></code> is the bottom bit of the sum, then <code><span class='Value'>m2</span><span class='Gets'>â†</span><span class='Value'>m</span><span class='Function'>&gt;â‰ </span><span class='Modifier'>`</span><span class='Value'>m</span></code> is the odd bits giving <code><span class='Function'>â‰ </span><span class='Modifier'>`</span><span class='Value'>m2</span></code> as the next sum bit, and again with every 4th bit and so on. The code in Hacker's Delight adds an extra shift <code><span class='Value'>m</span><span class='Gets'>â†</span><span class='Function'>Â»Â¬</span><span class='Value'>ğ•¨</span></code> instead of <code><span class='Value'>m</span><span class='Gets'>â†</span><span class='Function'>Â¬</span><span class='Value'>ğ•¨</span></code>, and compresses a copy of <code><span class='Value'>m</span></code> along with <code><span class='Value'>ğ•©</span></code>. Neither is needed: the line <code><span class='Value'>mv</span> <span class='Function'>=</span> <span class='Value'>mp</span> <span class='Value'>&amp;</span> <span class='Value'>m</span></code> and all manipulation of <code><span class='Value'>m</span></code> can be removed with no change in overall functionality.</p>
<p>All these xor-scans are expensive without a carry-less multiply and high-latency even with it, and it turns out it's possible to save a lot of work by not computing higher bits of the sum at every position. To begin explaining, I find it helpful to think of the movement in terms of how it bubbles the &quot;vacant&quot; bits corresponding to <code><span class='Number'>0</span></code> in <code><span class='Value'>ğ•¨</span></code> to the top. After <code><span class='Value'>i</span></code> steps of the algorithm, these bits are grouped in runs of <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code>, where the top bit hasn't yet moved. On the next step, runs are paired up, and the lower half of each pair moves up to merge with its partner. That is, <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code> vacant bits are swapped with any number of live bits, by shifting the live bits down <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code> spaces. Live bits must be moved when they have an odd number of runs below them, that is, when bit <code><span class='Value'>i</span></code> is 1 in the number of vacant bits below.</p>
<svg viewBox='-44 -36 447.2 168'>
  <g fill='currentColor' font-family='BQN,monospace' font-size='16'>
    <rect class='code' stroke-width='1.5' rx='12' x='-16' y='-28' width='391.2' height='152'/>
    <g class='bluegreen' opacity='0.3'>
      <path d='M52 17L52 111M90.4 17L90.4 111M128.8 17L128.8 111M167.2 17L167.2 111M205.6 17L205.6 111M244 17L244 111M282.4 17L282.4 111M320.8 17L320.8 111M359.2 17L359.2 111'/>
      <rect x='52' y='23' width='19.2' height='18'/>
      <rect x='109.6' y='23' width='28.8' height='18'/>
      <rect x='176.8' y='23' width='57.6' height='18'/>
      <rect x='272.8' y='23' width='9.6' height='18'/>
      <rect x='320.8' y='23' width='28.8' height='18'/>
      <rect x='52' y='87' width='48' height='18'/>
      <rect x='176.8' y='87' width='67.2' height='18'/>
      <rect x='320.8' y='87' width='28.8' height='18'/>
    </g>
    <g class='yellow' stroke-width='4' opacity='0.2'>
      <path d='M79 46L101.8 86M88.6 46L111.4 86M98.2 46L121 86M107.8 46L130.6 86M143.2 46L143.2 86M152.8 46L152.8 86M162.4 46L162.4 86M172 46L172 86M240.2 46L247.8 86M249.8 46L257.4 86M259.4 46L267 86M269 46L276.6 86M287.2 46L287.2 86M296.8 46L296.8 86M306.4 46L306.4 86M316 46L316 86M354.4 46L354.4 86'/>
    </g>
    <g class='purple' stroke-width='5'><path d='M109.6 43H176.8M272.8 43H320.8'/></g>
    <g class='purple' stroke-width='1.5'>
      <path d='M111.4 46L79 86M121 46L88.6 86M130.6 46L98.2 86M274.6 46L242.2 86'/>
    </g>
    <g class='green' stroke-width='5'><path d='M90.4 48H167.2M244 48H282.4'/></g>
    <text textLength='307.2' dy='0.32em' x='52' y='32'><tspan class='Number'>1</tspan>00000<tspan class='Number'>11</tspan>0000000<tspan class='Number'>1111</tspan>0000<tspan class='Number'>1</tspan>0000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <text textLength='307.2' dy='0.32em' x='52' y='96'><tspan class='Number'>1</tspan>0<tspan class='Number'>11</tspan>00000000000<tspan class='Number'>11111</tspan>00000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>0</text>
    <g font-size='10'><text textLength='307.2' dy='0.32em' x='52' y='-14'>10001000101100111111000100001110</text></g>
    <g text-anchor='end'>
      <text dy='0.33em' x='90.4' y='6'>3</text>
      <text dy='0.33em' x='128.8' y='6'><tspan class='Function'>6</tspan></text>
      <text dy='0.33em' x='167.2' y='6'><tspan class='Function'>7</tspan></text>
      <text dy='0.33em' x='205.6' y='6'>9</text>
      <text dy='0.33em' x='244' y='6'>9</text>
      <text dy='0.33em' x='282.4' y='6'><tspan class='Function'>12</tspan></text>
      <text dy='0.33em' x='320.8' y='6'>16</text>
      <text dy='0.33em' x='359.2' y='6'>17</text>
      <g font-size='12'>
        <text dy='0.33em' x='46' y='-14'><tspan class='Value'>ğ•¨</tspan></text>
        <text dy='0.33em' x='46' y='45'>bitwise</text>
        <text dy='0.33em' x='46' y='58'>aligned</text>
      </g>
      <text dy='0.33em' x='46' y='6'><tspan class='Function'>+</tspan><tspan class='Modifier'>`</tspan><tspan class='Function'>Â¬</tspan><tspan class='Value'>ğ•¨</tspan></text>
    </g>
    <g stroke='currentColor' stroke-width='0.7'><path d='M48 45L109.6 43M48 58L90.4 48'/></g>
  </g>
</svg>

<p>Guy Steele relies on the fact that this bit of the sum is the same as for the initial <code><span class='Value'>ğ•¨</span></code>, because it only changes at the top bit of a run, which hasn't moved yet. The boundaries of the computed masks are placed at these top bits, but they don't have to be. Since the mask value only affects live bits, it's safe to start anywhere within the run of <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code> vacant bits. In particular, if we split <code><span class='Value'>ğ•¨</span></code> into groups of length <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code>, we can use the mask value at the <em>end</em> of the group for all the bits inside: this is equal to the number of zero bits in <code><span class='Value'>ğ•¨</span></code> in or before the group, or, <code><span class='Function'>+</span><span class='Modifier'>`</span><span class='Value'>z</span></code>, where <code><span class='Value'>z</span></code> is the count of zeros in each group.</p>
<p>The required sums can be computed in log(w) instructions with pairwise combinations. For a given shift amount <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code>, compute counts of size <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code> recursively (beginning with <code><span class='Function'>Â¬</span><span class='Value'>ğ•¨</span></code>), and add them in pairs to get counts of size <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span><span class='Function'>+</span><span class='Number'>1</span></code>. This might look like <code><span class='Value'>b8</span><span class='Function'>=</span><span class='Paren'>(</span><span class='Value'>c4</span><span class='Function'>&gt;&gt;</span><span class='Number'>4</span><span class='Paren'>)</span><span class='Value'>&amp;h8</span><span class='Head'>;</span> <span class='Value'>c8</span><span class='Function'>=</span><span class='Paren'>(</span><span class='Value'>c4&amp;h8</span><span class='Paren'>)</span><span class='Function'>+</span><span class='Value'>b8</span></code> where <code><span class='Value'>i</span></code> is 3, and <code><span class='Value'>h8</span></code> has the low 4 bits set out of every 8. Then recursively get sums of size <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span><span class='Function'>+</span><span class='Number'>1</span></code>, and split them into sums of size <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code>, like <code><span class='Value'>s4</span><span class='Function'>=</span><span class='Paren'>(</span><span class='Value'>s8</span><span class='Function'>-</span><span class='Value'>b8</span><span class='Paren'>)</span><span class='Function'>|</span><span class='Paren'>(</span><span class='Value'>s8</span><span class='Function'>&lt;&lt;</span><span class='Number'>4</span><span class='Paren'>)</span></code>, with a few extra tricks for overflow handling for smaller sizes. After this computation the mask is found by selecting bit <code><span class='Value'>i</span></code> of the sum and copying <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code> times. The group size doesn't actually have to be equal to <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>i</span></code> but just has to be big enough that the sums don't overflowâ€”it's best to compute <code><span class='Value'>s8</span><span class='Function'>=</span><span class='Value'>c8*</span><span class='Number'>0x010101</span><span class='Value'>â€¦</span></code> and keep to a maximum group size of 8, assuming your machine words aren't wider than 256 bits. The full computation is three passes: one pass up for counts, one down for sums, and a last pass up to actually shift <code><span class='Value'>ğ•©</span></code>. While the instruction count can be small, this is much worse for latency than Guy Steele's two upwards passes that can be overlapped. In my tests I've found it's always best to compute the 1-shift mask with an xor-scan, as well as the 2-shift if a 64-bit carry-less multiply instruction is available.</p>
<h3 id="sparse-compress"><a class="header" href="#sparse-compress">Sparse compress</a></h3>
<p>When <code><span class='Value'>ğ•¨</span></code> is sparse (or <code><span class='Value'>ğ•©</span></code> for Indices), that is, has a small sum relative to its length, there are methods that lower the per-input cost by doing more work for each output.</p>
<p>The best-known sparse method is to work on a full word of bits. At each step, find the first index with count-trailing-zeros, and then remove that bit with a bitwise and, <code><span class='Value'>w</span> <span class='Value'>&amp;</span><span class='Function'>=</span> <span class='Value'>w</span><span class='Function'>-</span><span class='Number'>1</span></code> in C. However, this method has a loop whose length is the number of 1s in the word, a variable. CPUs are very good at predicting this length in benchmarks, but in practice it's likely to be less predictable! In CBQN it's only used for densities below 1/128, one bit every two words.</p>
<p>For marginal cases, I found a branchless algorithm that can work on blocks of up to <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>11</span></code> elements. The idea is to split each word into a few segments, and write the bits and relative offset for each segment to the appropriate position in the result of a zeroed buffer. Then traverse the buffer, maintaining bits and a cumulative offset. At each step, the index is obtained from those bits with count-trailing-zeros just as in the branching algorithm. The bits will all be removed exactly when the next segment is reached, so new values from the buffer can be incorporated just by adding them.</p>
<svg viewBox='-40 -80 1056 404'>
  <g fill='currentColor' font-family='BQN,monospace' font-size='16'>
    <rect class='code' stroke-width='1.5' rx='12' x='-24' y='-72' width='1024' height='388'/>
    <rect class='bluegreen' opacity='0.3' x='950' y='-60' width='36' height='364'/>
    <path stroke-width='1' stroke='currentColor' fill='none' d='M4 -8h-10v146h10M4 150h-10v146h10'/>
    <g class='bluegreen' stroke-width='3' stroke-linecap='round'>
      <path d='M238 5L282 0M238 56L282 36M238 107L282 180M238 163L282 180M238 214L282 180M238 265L282 288'/>
      <path d='M606 0L650 0M606 36L650 36M606 72L650 72M606 108L650 108M606 144L650 144M606 180L650 180M606 216L650 216M606 252L650 252M606 288L650 288'/>
      <path d='M670 12L670 24M670 48L670 60M670 84L670 96M670 120L670 132M670 156L670 168M670 192L670 204M670 228L670 240M670 264L670 276'/>
    </g>
    <text dy='0.33em' x='20' y='-48'>words split 24+24+16</text>
    <text dy='0.33em' x='288' y='-48'>zeroed buffer  <tspan class='String'>+</tspan>  bits | <tspan class='Modifier'>add</tspan><<24</text>
    <text dy='0.33em' x='656' y='-48'>trailing zeros of <tspan class='Number'>â†“</tspan>   +  8Ã—<tspan class='Modifier'>â†“</tspan> =</text>
    <text dy='0.33em' x='656' y='-20'>                         <tspan class='Modifier'>(Â¯2)</tspan></text>
    <text dy='0.33em' x='0' y='5'>00000000000000000000000<tspan class='Number'>1</tspan></text>
    <text dy='0.33em' x='0' y='56'><tspan class='Number'>1</tspan>00000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>000000<tspan class='Number'>1</tspan>00000</text>
    <text dy='0.33em' x='0' y='107'>0000000000000000</text>
    <text dy='0.33em' x='0' y='163'>000000000000000000000000</text>
    <text dy='0.33em' x='0' y='214'>0000<tspan class='Number'>1</tspan><tspan class='Number'>1</tspan>0000000000<tspan class='Number'>1</tspan>0000000</text>
    <text dy='0.33em' x='0' y='265'>0000000000<tspan class='Number'>1</tspan>00000</text>
    <text dy='0.33em' x='0' y='23'>sum=<tspan class='String'>1</tspan>, dest=<tspan class='String'>0</tspan>, add=<tspan class='Modifier'>2</tspan></text>
    <text dy='0.33em' x='0' y='74'>sum=<tspan class='String'>4</tspan>, dest=<tspan class='String'>1</tspan>, add=<tspan class='Modifier'>3</tspan></text>
    <text dy='0.33em' x='0' y='125'>sum=<tspan class='String'>0</tspan>, dest=<tspan class='String'>5</tspan>, add=<tspan class='Modifier'>3</tspan></text>
    <text dy='0.33em' x='0' y='181'>sum=<tspan class='String'>0</tspan>, dest=<tspan class='String'>5</tspan>, add=<tspan class='Modifier'>2</tspan></text>
    <text dy='0.33em' x='0' y='232'>sum=<tspan class='String'>3</tspan>, dest=<tspan class='String'>5</tspan>, add=<tspan class='Modifier'>3</tspan></text>
    <text dy='0.33em' x='0' y='283'>sum=<tspan class='String'>1</tspan>, dest=<tspan class='String'>8</tspan>, add=<tspan class='Modifier'>3</tspan></text>
    <text dy='0.33em' x='288' y='0'>00000000000000000000000<tspan class='Number'>1</tspan> | <tspan class='Modifier'>2</tspan><<24</text>
    <text dy='0.33em' x='288' y='36'><tspan class='Number'>1</tspan>00000000<tspan class='Number'>1</tspan>0<tspan class='Number'>1</tspan>000000<tspan class='Number'>1</tspan>00000 | <tspan class='Modifier'>3</tspan><<24</text>
    <text dy='0.33em' x='288' y='72'>0</text>
    <text dy='0.33em' x='288' y='108'>0</text>
    <text dy='0.33em' x='288' y='144'>0</text>
    <text dy='0.33em' x='288' y='180'>0000<tspan class='Number'>1</tspan><tspan class='Number'>1</tspan>0000000000<tspan class='Number'>1</tspan>0000000 | <tspan class='Modifier'>8</tspan><<24</text>
    <text dy='0.33em' x='288' y='216'>0</text>
    <text dy='0.33em' x='288' y='252'>0</text>
    <text dy='0.33em' x='288' y='288'>0000000000<tspan class='Number'>1</tspan>0000000000000 | <tspan class='Modifier'>3</tspan><<24</text>
    <text dy='0.33em' x='656' y='0'>00000000000000000000000<tspan class='Number'>1</tspan>,<tspan class='Modifier'>  0</tspan></text>
    <text dy='0.33em' x='656' y='36'><tspan class='Number'>1</tspan>00000000101000000100000,<tspan class='Modifier'>  3</tspan></text>
    <text dy='0.33em' x='656' y='72'>000000000<tspan class='Number'>1</tspan>01000000100000,<tspan class='Modifier'>  3</tspan></text>
    <text dy='0.33em' x='656' y='108'>00000000000<tspan class='Number'>1</tspan>000000100000,<tspan class='Modifier'>  3</tspan></text>
    <text dy='0.33em' x='656' y='144'>000000000000000000<tspan class='Number'>1</tspan>00000,<tspan class='Modifier'>  3</tspan></text>
    <text dy='0.33em' x='656' y='180'>0000<tspan class='Number'>1</tspan>1000000000010000000,<tspan class='Modifier'> 11</tspan></text>
    <text dy='0.33em' x='656' y='216'>00000<tspan class='Number'>1</tspan>000000000010000000,<tspan class='Modifier'> 11</tspan></text>
    <text dy='0.33em' x='656' y='252'>0000000000000000<tspan class='Number'>1</tspan>0000000,<tspan class='Modifier'> 11</tspan></text>
    <text dy='0.33em' x='656' y='288'>0000000000<tspan class='Number'>1</tspan>0000000000000,<tspan class='Modifier'> 14</tspan></text>
    <text dy='0.33em' x='934' y='0'>â†’  23</text>
    <text dy='0.33em' x='934' y='36'>â†’  24</text>
    <text dy='0.33em' x='934' y='72'>â†’  33</text>
    <text dy='0.33em' x='934' y='108'>â†’  35</text>
    <text dy='0.33em' x='934' y='144'>â†’  42</text>
    <text dy='0.33em' x='934' y='180'>â†’  92</text>
    <text dy='0.33em' x='934' y='216'>â†’  93</text>
    <text dy='0.33em' x='934' y='252'>â†’ 104</text>
    <text dy='0.33em' x='934' y='288'>â†’ 122</text>
    <g font-size='12'><text dy='0.33em' x='20' y='-28'>(little-endian bit order)</text></g>
    <g font-size='26'>
      <text dy='0.33em' x='-4' y='-42'><tspan class='Value'>ğ•©</tspan></text>
      <text dy='0.33em' x='950' y='-42'><tspan class='Function'>/</tspan><tspan class='Value'>ğ•©</tspan></text>
    </g>
  </g>
</svg>

<h3 id="grouped-compress"><a class="header" href="#grouped-compress">Grouped compress</a></h3>
<p>The sparse method can also be adapted to find groups of 1s instead of individual 1s, by searching for the first 1 and then the first 0 after that. This is useful if <code><span class='Value'>ğ•¨</span></code> changes value rarely, that is, if <code><span class='Function'>+</span><span class='Modifier'>Â´</span><span class='Function'>Â»</span><span class='Modifier2'>âŠ¸</span><span class='Function'>&lt;</span><span class='Value'>ğ•¨</span></code> is small. Computing this value can be expensive so it's best to compute the threshold first, then update it in blocks and stop if it exceeds the threshold.</p>
<p>For copying medium-sized cells with memcpy, all the branching here is pretty cheap relative to the actual operation, and it may as well be used all the time. This may not be true for smaller cells copied with overwriting, but I haven't implemented overwriting so I'm not sure.</p>
<h2 id="higher-ranks"><a class="header" href="#higher-ranks">Higher ranks</a></h2>
<p>When replicating along the first axis only, additional axes only change the element size (these are the main reason why a large-element method is given). Replicating along a later axis offers a few opportunities for improvement relative to replicating each cell individually. See also <a href="select.html#multi-axis-selection">multi-axis Select</a>.</p>
<p>Particularly for boolean <code><span class='Value'>ğ•¨</span></code>, Select is usually faster than Replicate (a major exception is for a boolean <code><span class='Value'>ğ•©</span></code>). Simply replacing <code><span class='Function'>/</span></code> with <code><span class='Function'>/</span><span class='Modifier'>Â¨</span><span class='Modifier2'>âŠ¸</span><span class='Function'>âŠ</span></code> (after checking length agreement) could be an improvement. It's probably best to compute the result shape first to avoid doing any work if it's empty. Similarly, if early result axes are small then the overhead of separating out Indices might make it worse than just doing the small number of Replicates.</p>
<p>Some other tricks are possible for boolean <code><span class='Value'>ğ•¨</span></code>. If there's a large enough unchanged axis above, perhaps with <code><span class='Value'>ğ•¨</span><span class='Function'>/</span><span class='Modifier2'>â‰</span><span class='Number'>1</span><span class='Value'>ğ•©</span></code>, then <code><span class='Value'>ğ•¨</span></code> can be repeated to act on virtual rows consisting of multiple rows of <code><span class='Value'>ğ•©</span></code> (the last one can be short). I think this only ends up being useful when <code><span class='Value'>ğ•©</span></code> is boolean. But we can also combine compress along several axes, as multi-axis <code><span class='Function'>â¥Š</span><span class='Value'>ğ•¨</span><span class='Function'>/</span><span class='Value'>ğ•©</span></code> is <code><span class='Paren'>(</span><span class='Function'>âˆ§</span><span class='Modifier'>âŒœÂ´</span><span class='Value'>ğ•¨</span><span class='Paren'>)</span><span class='Function'>/</span><span class='Modifier2'>â—‹</span><span class='Function'>â¥Š</span><span class='Value'>ğ•©</span></code>: the previous method is a bit like a specialization where entries of <code><span class='Value'>ğ•¨</span></code> other than the last are lists of <code><span class='Number'>1</span></code>s. This is particularly nice if <code><span class='Value'>ğ•©</span></code> as a whole is small, but even if <code><span class='Value'>ğ•¨</span></code> will eventually be converted to indices, it's a faster way to combine the bottom few levels if they're fairly dense.</p>
<h2 id="indices-inverse-counting"><a class="header" href="#indices-inverse-counting">Indices inverse (counting)</a></h2>
<p>Counting indices with <code><span class='Function'>/</span><span class='Modifier'>â¼</span></code>, sometimes called &quot;histogramming&quot;, has a wide variety of uses. While a programmer might use it directly, it also forms half of <a href="sort.html#distribution-sorts">counting sort</a> and is needed to get the result lengths in Group (<code><span class='Function'>âŠ”</span></code>). It poses a few non-obvious implementation challenges. For the result length we need to know the maximum argument value, but an extra pass for it can be slow (a combined <code><span class='Value'>n</span><span class='Function'>â†‘/</span><span class='Modifier'>â¼</span></code> with result length <code><span class='Value'>n</span></code> would avoid this). For the best result <em>type</em>, ideally we'd know the maximum count, but this isn't easy to compute. And the natural implementation of counting itself is relatively slow simply because it's scalar, but it also gets quite a bit worse if indices repeat because each increment at the same location depends on the previous one.</p>
<p>A general method of dependency-breaking described <a href="https://palaiologos.rocks/posts/fastent/">here</a> is to allocate multiple count arrays and cycle through them, adding up at the end. Of course this is only good if the range is much smaller than the number of values.</p>
<h3 id="count-type-wrangling"><a class="header" href="#count-type-wrangling">Count type wrangling</a></h3>
<p>If the argument has a small type, then the result size is limited: for example <code><span class='Function'>/</span><span class='Modifier'>â¼</span></code> of an i8 array can only have indices 0 to 127, for a maximum length of 128. This size may be much smaller than the argument length. In such a case it's best to allocate (and zero-initialize) a maximum-size result right away, and trim down later if necessary. The result length can be found by taking a running sum of counts, stopping when it adds up to the argument length. A possible trick is to leave room for the negative values of the domain as well, so no range checking is needed. These counts don't need to be initialized: instead, if the sum of the non-negative counts doesn't get up to the argument length, there was a negative input and we should give an error. The range tricks are primarily useful for a non-SIMD implementation, because range computation with SIMD is cheap and is useful for enabling count-by-summing as well.</p>
<p>In other cases, we should compute the argument range and consequently result length right away. If the result is much larger than the argument, we need to do processing in the argument domain as much as possible, and avoid allocating the result with a larger type than necessary.</p>
<p>The result type can be tested using a scratch result with <a href="search.html#sparse-and-reverse-lookups">sparse initialization</a>, that is, instead of filling the result with zeros, take an initial argument pass to zero out each value found in the argument. Then count into this buffer; since scanning it at the end would be too slow the maximum has to be updated at each step. I've used the pattern <code><span class='Value'>maxcount</span> <span class='Function'>|=</span> <span class='Function'>++</span><span class='Value'>tab</span><span class='Bracket'>[</span><span class='Value'>x</span><span class='Bracket'>[</span><span class='Value'>i</span><span class='Bracket'>]]</span></code> for this with unsigned <code><span class='Value'>maxcount</span></code>, so that if any count gets to <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Value'>k</span></code> then <code><span class='Value'>maxcount</span></code> will too (assuming the table type has more than <code><span class='Value'>k</span></code> bits). While this may allocate a large table, it only touches the parts corresponding to argument values, making the cost is proportional to the argument length. But it's fairly expensive per-element. We only use it in CBQN if the result is over 8 times as long as the argument. Maybe it's worth mentioning that streaming algorithms like <a href="https://en.wikipedia.org/wiki/Misra%E2%80%93Gries_heavy_hitters_algorithm">Misra-Gries</a> exist to find frequent elements without allocating much space, but none of them seem like they'd be practical here.</p>
<h4 id="mod-overflow-representation"><a class="header" href="#mod-overflow-representation">Mod-overflow representation</a></h4>
<p>If the wanted result type is at least as large as the argument type, a compressed representation becomes viable. For concreteness let's say we expect an i16 or larger result. We will allocate an i16 result to store the counts modulo <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code>, plus an overflow vector which will end up with <code><span class='Function'>âŒŠ</span><span class='Value'>c</span><span class='Function'>Ã·</span><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code> copies of each index with count <code><span class='Value'>c</span></code>, so that it has maximum length <code><span class='Function'>âŒŠ</span><span class='Paren'>(</span><span class='Function'>â‰ </span><span class='Value'>ğ•©</span><span class='Paren'>)</span><span class='Function'>Ã·</span><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code>. To compute this result we simply count normally, but stop every <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code> input values to flush any counts that have wrapped into the negatives, preferably with a SIMD search (only one count can wrap per round, amortized, so there won't be many hitsâ€”but we do need the small result length implied by a small argument type here). Since every round starts with counts below <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code>, and adds at most <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code> to any count, a count that wraps remains below 0. Getting to the final result from this representation no longer depends on the argument type (the overflow vector should be full-width), so it can be done with a shared function. If there are any overflowed indices, the result needs to be widened, and then we have to add <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code> to it at each one. In extreme cases this could trigger a second overflow and a 64-bit output type.</p>
<p>If the argument and result are both large, then to maintain cache locality the argument should probably be radix-<a href="search.html#partitioning">partitioned</a>. Among other possibilities, this allows the i16 overflow scheme to be used again because we can partition down so that either an argument segment is smaller than <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>15</span></code> and no overflow is possible, or the result segment has size <code><span class='Number'>2</span><span class='Function'>â‹†</span><span class='Number'>16</span></code> and flushing overflows isn't too expensive.</p>
<h3 id="simd-counting"><a class="header" href="#simd-counting">SIMD counting</a></h3>
<p>Because of the arbitrary range of the output, counting can't generally be expressed with SIMD instructions (scatters don't countâ€¦ no pun intended). Small-range cases do sometimes allow useful SIMD, and it can be used as part of a runs-adaptive method. To check whether these optimizations apply, start with a SIMD scan on a block to get statistics like the minimum, maximum, and number of unequal adjacent indices.</p>
<p>If the range is small enough, comparing to all possible values and summing becomes viable. A somewhat complicated structure is needed to use registers effectively: we don't want to reload values too many times, but we can't keep too many counts active at once. In CBQN we work in blocks that fit in L1, and have one pass that does 4 comparisons per load to get 4 sums, and another for 1 sum (rounding the range up to use 4 only would also be possible). One of the sums can be computed by subtracting the rest from the number of indices; this optimization also handles the case with all equal indices in constant time.</p>
<p>A run of equal indices ends when an index isn't equal to the next one, and its length is that ending position minus the ending position for the previous run. So a run-based counting algorithm is to mark the runs with a SIMD comparison, and iterate over these with the normal scalar method, count-trailing-zeros and <code><span class='Value'>m</span> <span class='Value'>&amp;</span><span class='Function'>=</span> <span class='Value'>m</span><span class='Function'>-</span><span class='Number'>1</span></code>. Forcing the end of each vector to be a boundary by or-ing a trailing bit into the mask avoids some complications. In CBQN I also added a branchless step that conditionally handles this final run, allowing the main loop to be unrolled by a factor of 2 which might be more predictable.</p>
<p>Scatters aren't much better than scalar writes, but the AVX-512CD conflict detection instruction should in theory provide the perfect tool for using them effectively. However, it does not. What we'd like to do is find a mask for unique indices and the number of duplicates each one has, gather the corresponding table values, add the number of duplicates plus one, and masked-scatter back to the table. vpconflictd returns the mask of which <em>preceding</em> elements are equal for each element, so summing this gives the number of duplicates at the last copy. But it doesn't indicate which elements are last copies! There are various cheesy workarounds to try, such as or-ing all the masks together to test which bits aren't there, or even calling vpconflictd again on the reverse (aside, I still don't get why Intel put a vector lzcnt in the same instruction set). I fiddled around with this on Skylake-X and couldn't improve on the basic scalar code, but maybe it's worth a try on AMD which has a real vpconflictd implementation instead of Intel's slow microcode.</p>
<p>The problem of histogramming 1-byte values with AVX-512 has seen a significant amount of effort, with the main idea being to group on the top 2 bits and sum 1-hot representations <code><span class='Number'>1</span> <span class='Function'>&lt;&lt;</span> <span class='Value'>low6</span></code> within each group; see <a href="https://bitmath.blogspot.com/2024/11/histogramming-bytes-with-positional.html">this post</a> and the linked improvements.</p>
<h3 id="counting-sorted-indices"><a class="header" href="#counting-sorted-indices">Counting sorted indices</a></h3>
<p>With a <a href="flagsort.html">known-sorted</a> argument, some shortcuts apply (and for some reason I keep wondering whether they can benefit counting sort, so I'll explicitly point out that <em>it's already sorted</em>). Most obviously, the maximum value is either the last or first element, depending on sort direction. And it's possible to find the result type with a simple scan; in fact to test whether any count can be larger than <code><span class='Value'>n</span></code> it's sufficient to check elements spaced <code><span class='Value'>n</span><span class='Function'>Ã·</span><span class='Number'>2</span></code> apart, with further inspection if two but not three of these are equal. But once the boolean type is ruled out, a method using the modulus-plus-overflow representation like <a href="#mod-overflow-representation">this section</a> to defer the type check seems more versatile, as I'll describe.</p>
<p>With sorted indices, flushing the count array by scanning is no longer needed, removing the downside of the small modulus for an i8 result type. Instead we can count in blocks of 128, and then just check the count of the block's first element, which may have started with a nonzero value causing it to overflow. But if the block starts and ends with the same value, we can skip that and dump it as an overflow right away. Better still, start a galloping search to find how many complete blocks the run spans in logarithmic time. Storing overflows as repeated valuesâ€”effectively counting in unaryâ€”would bring us back down to linear, so they should be stored along with counts here (there may still be duplicate values). So, the allocations are the i8 result, an overflow vector with length n/128, and corresponding counts, both as full-width ints. If there are overflows, the correct type is easy to find in one pass, since they have to be in order. As in the unsorted case, expanding to this type doesn't depend on the original argument type.</p>
<p>As for counting within a block, the unsorted methods can of course be used. However, because duplicate indices all come next to each other, repeats are more likely and also are completely handled by run detection. In CBQN, we skip any range-checking, and check for runs one vector at a time: we load two offset vectors and compare to get run boundaries, then count by iterating over them if the number of boundaries is less than half the number of elements, or otherwise with scalar increments. This leaves a slight overhead from branch misprediction near the boundary which could perhaps be improved.</p>
